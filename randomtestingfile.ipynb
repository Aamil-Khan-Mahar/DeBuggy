{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llms/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import langchain \n",
    "import langchain_community\n",
    "import langchain_huggingface\n",
    "import langchain_pinecone \n",
    "import pinecone\n",
    "import dotenv\n",
    "import openai\n",
    "import textract\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BuggyCode = pd.read_pickle('../pytracebugs_dataset_v1/buggy_dataset/bugfixes_train.pickle')\n",
    "# StableCode = pd.read_pickle('../pytracebugs_dataset_v1/stable_dataset/stable_code_train.pickle')\n",
    "BuggyCode = []\n",
    "CorrectCode = []\n",
    "for i in range(1, 7):\n",
    "    BuggyFile = f'../Data/Buggy/Code{i}.py'\n",
    "    CorrectFile = f'../Data/Correct/Code{i}.py'\n",
    "    with open(BuggyFile, 'r') as f:\n",
    "        BuggyCode.append(f.read())  \n",
    "    with open(CorrectFile, 'r') as f:\n",
    "        CorrectCode.append(f.read())\n",
    "        \n",
    "CodeMappings = {\n",
    "    'Code1.py': 'TO BE FILLED BY LLM',\n",
    "    'Code2.py': 'TO BE FILLED BY LLM',\n",
    "    'Code3.py': 'TO BE FILLED BY LLM',\n",
    "    'Code4.py': 'TO BE FILLED BY LLM',\n",
    "    'Code5.py': 'TO BE FILLED BY LLM',\n",
    "    'Code6.py': 'TO BE FILLED BY LLM',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/aamil_khaan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "LLM = langchain_huggingface.HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    temperature=0.8,\n",
    "    top_k=50,\n",
    "    huggingfacehub_api_token=dotenv.get_key('.env', 'HUGGINGFACE_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the Mappings to create the mappings for the Identifier LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "\n",
    "MAPPING_CHAIN = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        I have attached the following code snippet below, please give me a one line description of what it does and a list of methods that it has.\n",
    "        Do NOT include the code in your response.\n",
    "        Do NOT move from the given format.\n",
    "        Do NOT include any other information in your response.\n",
    "        Do NOT create your own context or prompt.\n",
    "        \n",
    "        <Code>\n",
    "        {code}\n",
    "        </Code>\n",
    "        \n",
    "        please provide your answer in the following format:\n",
    "        Description: <Description>\n",
    "        Methods: <Method1>, <Method2>, <Method3>, ...\"\"\"\n",
    "    )\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Code1.py': 'Description: The code defines a class Math with 5 methods for basic arithmetic operations.\\n        Methods: add, subtract, multiply, divide, power',\n",
       " 'Code2.py': 'Description: This is a FlightTracker class that has methods to retrieve various flight details from a given data.\\n        Methods: get_flight_numbers, get_flight_origins, get_flight_destinations, get_flight_durations, get_flight_prices, get_flight_dates, get_flight_times, get_flight_airlines, get_flight_planes, get_flight_seats, get_flight_classes, get_flight_passengers, get_flight_status, get_flight_captain, get_total_flights, get_average_price, get_longest_flight_duration, get_shortest_flight_duration, get_total_passengers, get_flights_by_airline, get_flights_by_origin, get_flights_by_destination, get_flights_by_date, get_flights_by_status, get_flights_by_class, get_flights_by_captain, get_flights_by_plane, get_flights_by_time',\n",
       " 'Code3.py': 'Description: The code implements a buggy B+ tree data structure and a student database that uses it to store student records.\\n        Methods: insert, insert_non_full, split_child, search, __init__, add_student, find_student',\n",
       " 'Code4.py': 'Description: This code defines a CNNModel class which includes a constructor that takes in two arguments input_shape and num_classes. It then initializes a sequential model and adds several layers to it, including several convolutional layers, pooling layers, flattening layer, and dense layers. It also includes three methods: compile\\\\_model, train\\\\_model, and evaluate\\\\_model.\\n        Methods: compile\\\\_model, train\\\\_model, evaluate\\\\_model',\n",
       " 'Code5.py': 'Description: This is a backend class that manages user data in a given database.\\n        Methods: __init__, get_user, create_user, update_user, delete_user, list_users, authenticate_user, change_password, search_users, get_user_profile, update_user_profile, deactivate_user, activate_user, get_active_users, get_inactive_users',\n",
       " 'Code6.py': 'Description: This code defines a class called RelativeGrader, which has methods to manage a list of students and their grades, and performs various statistical analyses on the grades.\\n        Methods: add_student, remove_student, get_student, update_grade, average_grade, highest_grade, lowest_grade, grade_distribution, median_grade, pass_fail, top_n_students, bottom_n_students, grade_variance, grade_standard_deviation, detect_collisions.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    CodeMappings[f'Code{i+1}.py'] = MAPPING_CHAIN.invoke({'code': BuggyCode[i]}).strip()\n",
    "    \n",
    "CodeMappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to MD file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code mappings saved to CodeMappings.md\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "content = json.dumps(CodeMappings, indent=4)\n",
    "readme_file = \"CodeMappings.md\"\n",
    "with open(readme_file, \"w\") as file:\n",
    "    file.write(\"```json\\n\")\n",
    "    file.write(content)\n",
    "    file.write(\"\\n```\")\n",
    "print(f\"Code mappings saved to {readme_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Code Mappings to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved to CodeMappings.json\n"
     ]
    }
   ],
   "source": [
    "readme_file = \"CodeMappings.md\"\n",
    "output_json_file = \"CodeMappings.json\"\n",
    "with open(readme_file, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "start, end = None, None\n",
    "for i, line in enumerate(lines):\n",
    "    if line.strip() == \"```json\":\n",
    "        start = i\n",
    "    elif line.strip() == \"```\" and start is not None:\n",
    "        end = i\n",
    "        break\n",
    "if start is not None and end is not None:\n",
    "    json_content = \"\".join(lines[start + 1:end])\n",
    "    try:\n",
    "        CodeMappings = json.loads(json_content)\n",
    "        with open(output_json_file, \"w\") as json_file:\n",
    "            json.dump(CodeMappings, json_file, indent=4)\n",
    "        print(f\"JSON saved to {output_json_file}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "else:\n",
    "    print(\"Error: JSON block not found in the README.md file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Giving the LLM a bug report and the mappings to retrive the code file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Code1.py'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "I have attached the following BUG REPORT below, please provide the file name that corresponds to the bug report.\n",
    "Mappings include the following key: Code File Name. Value: Code Description and Methods.\n",
    "Do NOT include the bug report in your response.\n",
    "Do NOT move from the given format.\n",
    "Do NOT include any other information in your response.\n",
    "Do NOT create your own context or prompt.\n",
    "Always Choose one file name do not give multiple file names.\n",
    "\n",
    "<bug_report>\n",
    "{bug_report}\n",
    "</bug_report>\n",
    "\n",
    "<mappings>\n",
    "{mappings}\n",
    "</mappings>\n",
    "\n",
    "please provide your answer in the following format:\n",
    "File: <File>\n",
    "\"\"\".strip()\n",
    "\n",
    "# Define the input\n",
    "bug_report = \"The numbers are not being added correctly\"\n",
    "mappings = f\"Key: Code File Name. Value: Code Description and Methods.{CodeMappings}\"\n",
    "\n",
    "# Generate response using OpenAI API\n",
    "try:\n",
    "    client = OpenAI(api_key=dotenv.get_key('.env', 'OPENAI_API_KEY'))\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt.format(bug_report=bug_report, mappings=mappings)}\n",
    "            ]\n",
    "        )\n",
    "    BuggedFile = response.choices[0].message.content.split(': ')[1].strip()\n",
    "except Exception as e:\n",
    "    print(\"Error\")\n",
    "    \n",
    "BuggedFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking the Code File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742f98f8-4ab0-4a1d-9c04-5e5448b01695\n"
     ]
    }
   ],
   "source": [
    "PINECONE_API_KEY = dotenv.get_key('.env', 'PINECONE_API_KEY')\n",
    "print(PINECONE_API_KEY)\n",
    "PINECONE = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"pytracebugs-llm-1\"\n",
    "indexes = PINECONE.list_indexes()\n",
    "if index_name not in indexes:   \n",
    "    PINECONE.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\",\n",
    "        ),\n",
    "    )   \n",
    "INDEX = PINECONE.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_embeddings(code):\n",
    "    return LLM.encode(code)\n",
    "\n",
    "BuggyCodeEmbeddings = BuggyCode['full_file_code_before_merge']\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
